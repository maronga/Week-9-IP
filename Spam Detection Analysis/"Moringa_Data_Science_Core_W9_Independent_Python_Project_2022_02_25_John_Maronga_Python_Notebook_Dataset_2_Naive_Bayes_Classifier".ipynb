{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " \"Moringa_Data_Science_Core_W9_Independent_Python_Project_2022_02_25_John_Maronga_Python_Notebook_Dataset_2_Naive_Bayes_Classifier\".ipynb",
      "provenance": [],
      "collapsed_sections": [
        "kLG2VTrnTvYL",
        "XecOwPNorl2W",
        "J4wfHZwQrs-t",
        "a9BPYqunry97",
        "7KMRBJ7zr9HD",
        "zSGyg6kWsBUl",
        "iUNbvIvnT7ep",
        "OI3P3YnHUEBk",
        "ckfufNrcUHeH",
        "6XC_g-zKxe-r",
        "FlBMxEDBUc9B",
        "rF2ABPsHUtbZ",
        "vTbdjSrhVIiT",
        "lQ2G4ZPDVOXE",
        "xrmHVMVsVS--",
        "HPQviDmNtta8",
        "qjFHK1CKty7o",
        "HSsicSdvt4Zs"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maronga/Week-9-IP/blob/main/Spam%20Detection%20Analysis/%22Moringa_Data_Science_Core_W9_Independent_Python_Project_2022_02_25_John_Maronga_Python_Notebook_Dataset_2_Naive_Bayes_Classifier%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMxtPsqcTsSH"
      },
      "source": [
        "# Spam detection in the Spambase Dataset using the Naive Bayes Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLG2VTrnTvYL"
      },
      "source": [
        "## 1. Defining the Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XecOwPNorl2W"
      },
      "source": [
        "### a) Specifying the Data Analytic Question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ozBnKfehSAw"
      },
      "source": [
        "> Make a prediction if an email is a spam or not using the Spambase Data Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4wfHZwQrs-t"
      },
      "source": [
        "### b) Defining the Metric for Success"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model will be considered successfull if when it's able to correctly and accurately predict that an email is a spam or not. The minimum accuracy level can be set as 80%."
      ],
      "metadata": {
        "id": "d4LljwDAgxCM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9BPYqunry97"
      },
      "source": [
        "### c) Understanding the context "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Dataset focuses on classifying Email as Spam or Non-Spam by frequency of word or character. The dataset was developed at Hewlett-Packard Labs and was donated by George Forman on July 1999 (Mark Hopkins, Erik Reeber, George Forman, Jaap Suermondt, 1999). The dataset contains 4601 instances and 58 variables. It contains two fields “Spam” and “Not Spam” for prediction. It is multivariate, real dataset mainly used for classification of attributes."
      ],
      "metadata": {
        "id": "so1nqVUUn9uH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMRBJ7zr9HD"
      },
      "source": [
        "### d) Recording the Experimental Design"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset\n",
        "\n",
        "Reading the dataset\n",
        "\n",
        "Checking the dataset\n",
        "\n",
        "Exploratory Data Analysis\n",
        "\n",
        "Implementing the Solution\n",
        "\n",
        "Challenging the solution\n",
        "\n",
        "Follow up question"
      ],
      "metadata": {
        "id": "My7XR9zEoVX7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSGyg6kWsBUl"
      },
      "source": [
        "### e) Data Relevance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datalink https://archive.ics.uci.edu/ml/datasets/spambase \n",
        "\n",
        "The dataset was created by Mark Hopkins, Erik Reeber, George Forman, Jaap Suermondt on July 1999\n",
        "\n",
        "The collection of spam e-mails came from the creators' postmaster and individuals who had filed spam. Their collection of non-spam e-mails came from filed work and personal e-mails, and hence the word 'george' and the area code '650' are indicators of non-spam. These are useful when constructing a personalized spam filter. One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter."
      ],
      "metadata": {
        "id": "0SL2xXx0oqRv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUNbvIvnT7ep"
      },
      "source": [
        "## 2. Reading the Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import mean_squared_error,r2_score,accuracy_score,f1_score,classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "xjStSXFqqm69"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJn2KjW-WMlG"
      },
      "source": [
        "# Loading the Data from the source i.e. csv\n",
        "# ---\n",
        "# Dataset source = Dataset source = \n",
        "# ---\n",
        "#\n",
        "df=pd.read_csv('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI3P3YnHUEBk"
      },
      "source": [
        "\n",
        "\n",
        "## 3. Checking the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjSVNwgptHxY"
      },
      "source": [
        "# Determining the no. of records in our dataset\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHhTw5eKWr0n"
      },
      "source": [
        "# Previewing the top of our dataset\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9AzGcZFrIIr"
      },
      "source": [
        "# Previewing the bottom of our dataset\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8-dW4sQWzbc"
      },
      "source": [
        "# Checking whether each column has an appropriate datatype\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckfufNrcUHeH"
      },
      "source": [
        "## 4. External Data Source Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L4sl_0WXlbg"
      },
      "source": [
        "Making sure your data matches something outside of the dataset is very important. It allows you to ensure that the measurements are roughly in line with what they should be and it serves as a check on what other things might be wrong in your dataset. External validation can often be as simple as checking your data against a single number, as we will do here.\n",
        "\n",
        "An example would be suppose that you're working with a dataset on the population of countries during the year 2016. Validating such information with an external reliable resource such as World Bank Data would be important step to providing credibility to your dataset. Have a look at the following link for an example. [Link](https://rstudio-pubs-static.s3.amazonaws.com/182250_19977d0c5c06403fbad1e653850fc7c6.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XC_g-zKxe-r"
      },
      "source": [
        "### a.Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlBMxEDBUc9B"
      },
      "source": [
        "## 5. Tidying the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o_bQcT5W3Wz"
      },
      "source": [
        "# Checking for Outliers\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWlukLKUvFQN"
      },
      "source": [
        "# Checking for Anomalies\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvCYb6dgW4yh"
      },
      "source": [
        "# Identifying the Missing Data\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpsDGKZHsf_W"
      },
      "source": [
        "# Dealing with the Missing Data\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-4I__6Os4C5"
      },
      "source": [
        "# More data cleaning procedures\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rF2ABPsHUtbZ"
      },
      "source": [
        "## 6. Exploratory Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nnRToniXGDK"
      },
      "source": [
        "# Ploting the bivariate summaries and recording our observations\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UzyQC6kmdBi"
      },
      "source": [
        "# Data Reduction\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTbdjSrhVIiT"
      },
      "source": [
        "## 7. Implementing the Solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJLZaRzJXJ3w"
      },
      "source": [
        "# Implementing the Solution\n",
        "# "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ2G4ZPDVOXE"
      },
      "source": [
        "## 8. Challenging the solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWVGKGuiYMWg"
      },
      "source": [
        "> The easy solution is nice because it is, well, easy, but you should never allow those results to hold the day. You should always be thinking of ways to challenge the results, especially if those results comport with your prior expectation.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3x3SXZ4XT_L"
      },
      "source": [
        "# Reviewing the Solution \n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrmHVMVsVS--"
      },
      "source": [
        "## 9. Follow up questions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pth2qSWhuBIy"
      },
      "source": [
        "> At this point, we can refine our question or collect new data, all in an iterative process to get at the truth.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPQviDmNtta8"
      },
      "source": [
        "### a). Did we have the right data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjFHK1CKty7o"
      },
      "source": [
        "### b). Do we need other data to answer our question?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSsicSdvt4Zs"
      },
      "source": [
        "### c). Did we have the right question?"
      ]
    }
  ]
}